namespace: confighubplaceholder

backend:
  replicas: 1
  image:
    repository: ghcr.io/confighubai/cubbychat/backend
    tag: 1.1.4
  resources:
    requests:
      memory: "100Mi"
      cpu: "100m"
    limits:
      memory: "200Mi"
      cpu: "500m"
  env:
    chatTitle: "AI Chat"
    ollamaUrl: "http://ollama:11434"
    ollamaModel: "tinyllama"
    databaseUrl: "postgres://admin:password@postgres:5432/chatdb"
    port: "8080"
    region: "dev"
    role: "development"
  ingress:
    host: base.local.cubby.bz

frontend:
  replicas: 1
  image:
    repository: ghcr.io/confighubai/cubbychat/frontend
    tag: 1.1.4
  resources:
    requests:
      memory: "100Mi"
      cpu: "100m"
    limits:
      memory: "200Mi"
      cpu: "500m"
  ingress:
    host: base.local.cubby.bz

postgres:
  replicas: 1
  image:
    repository: postgres
    tag: "16"
  resources:
    requests:
      memory: "100Mi"
      cpu: "100m"
    limits:
      memory: "200Mi"
      cpu: "500m"
  storage:
    size: 5Gi
  env:
    database: "chatdb"
    user: "admin"
    password: "password"

ollama:
  replicas: 1
  image:
    repository: ollama/ollama
    tag: 0.11.11
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  modelLoader:
    image:
      repository: curlimages/curl
      tag: latest
    resources:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    modelName: "tinyllama"
